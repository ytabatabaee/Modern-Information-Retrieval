{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_nMeRVcDMxQC"
   },
   "source": [
    "# Classification and Clustering of Text articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6kLwEkjWMxQS"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_b1eQD1MxQW"
   },
   "outputs": [],
   "source": [
    "# importing Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from scipy.stats import t\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2rWbQSOjMxQw"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_json('data/train.json')[:10000]\n",
    "validation_data = pd.read_json('data/validation.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2056,
     "status": "ok",
     "timestamp": 1589546309331,
     "user": {
      "displayName": "Yasamin Tabatabaee",
      "photoUrl": "",
      "userId": "07445355406834081164"
     },
     "user_tz": -270
    },
    "id": "81N4v2NDMxQ7",
    "outputId": "48b84dbc-af30-4f9d-8c5e-3cd011e7318d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every day, cubicle-dwellers get up from their ...</td>\n",
       "      <td>4</td>\n",
       "      <td>MobileAccess Networks Strengthens Signals for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New 1.8-inch hard drives may boost battery lif...</td>\n",
       "      <td>4</td>\n",
       "      <td>Hitachi Drives Consumer Storage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A hearing into allegations of racism against t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Cricket: Zim race probe halted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The prospect that a tropical storm and a hurri...</td>\n",
       "      <td>4</td>\n",
       "      <td>Simultaneous Tropical Storms are Very Rare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Second seed Jiri Novak and number three Guille...</td>\n",
       "      <td>2</td>\n",
       "      <td>NOVAK AND CANAS SET UP SHOWDOWN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  category  \\\n",
       "0  Every day, cubicle-dwellers get up from their ...         4   \n",
       "1  New 1.8-inch hard drives may boost battery lif...         4   \n",
       "2  A hearing into allegations of racism against t...         1   \n",
       "3  The prospect that a tropical storm and a hurri...         4   \n",
       "4  Second seed Jiri Novak and number three Guille...         2   \n",
       "\n",
       "                                               title  \n",
       "0  MobileAccess Networks Strengthens Signals for ...  \n",
       "1                    Hitachi Drives Consumer Storage  \n",
       "2                     Cricket: Zim race probe halted  \n",
       "3         Simultaneous Tropical Storms are Very Rare  \n",
       "4                    NOVAK AND CANAS SET UP SHOWDOWN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2018,
     "status": "ok",
     "timestamp": 1589546309335,
     "user": {
      "displayName": "Yasamin Tabatabaee",
      "photoUrl": "",
      "userId": "07445355406834081164"
     },
     "user_tz": -270
    },
    "id": "3CPsv_kJMxRH",
    "outputId": "b81c0785-517a-499e-b266-da4a978f6144"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>body</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>The first targeted flyby of Titan occurs on Tu...</td>\n",
       "      <td>Titan flyby overview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Officials can not estimate all casualties as s...</td>\n",
       "      <td>Dubai terminal construction collapse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>A patch has been issued for the JpegOfDeath ho...</td>\n",
       "      <td>Will JpegOfDeath Help Slay Microsoft?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Marsh  amp; McLennan Companies Inc., the insur...</td>\n",
       "      <td>Update 2: Marsh Seeks Incentive Fees for Settl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A Singaporean IT products distributor is intro...</td>\n",
       "      <td>PC distributor puts RFID tags in goods</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                               body  \\\n",
       "0         4  The first targeted flyby of Titan occurs on Tu...   \n",
       "1         1  Officials can not estimate all casualties as s...   \n",
       "2         4  A patch has been issued for the JpegOfDeath ho...   \n",
       "3         3  Marsh  amp; McLennan Companies Inc., the insur...   \n",
       "4         4  A Singaporean IT products distributor is intro...   \n",
       "\n",
       "                                               title  \n",
       "0                               Titan flyby overview  \n",
       "1               Dubai terminal construction collapse  \n",
       "2              Will JpegOfDeath Help Slay Microsoft?  \n",
       "3  Update 2: Marsh Seeks Incentive Fees for Settl...  \n",
       "4             PC distributor puts RFID tags in goods  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yBKkh_AKMxRl"
   },
   "outputs": [],
   "source": [
    "def text_to_words(text):\n",
    "    replace_punctuation = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    return text.translate(replace_punctuation).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all of terms in data set\n",
    "\n",
    "def get_vocabulary(data):\n",
    "    terms = set()\n",
    "    for doc_idx in data.index:\n",
    "        body_words = text_to_words(data.loc[doc_idx].body)\n",
    "        title_words = text_to_words(data.loc[doc_idx].title)\n",
    "        terms.update(body_words + title_words)\n",
    "    return list(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2Jf7diWR92k"
   },
   "outputs": [],
   "source": [
    "# Building static tf-idf dicts\n",
    "\n",
    "def build_tf(data, terms): \n",
    "    n = data.shape[0]\n",
    "    v = len(terms)\n",
    "    weight_matrix = np.zeros((n, v))\n",
    "    \n",
    "    for doc_idx in data.index:\n",
    "        doc = data.loc[doc_idx]\n",
    "        body_words = text_to_words(doc.body)\n",
    "        title_words = text_to_words(doc.title)\n",
    "        weight_matrix[doc_idx] = np.zeros(v)\n",
    "        for w in set(body_words + title_words):\n",
    "            if w in terms:\n",
    "                weight_matrix[doc_idx][terms.index(w)] = body_words.count(w) + title_words.count(w)\n",
    "    \n",
    "    return pd.DataFrame(weight_matrix, index=data.index, columns=terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = get_vocabulary(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat = build_tf(train_data[:100], terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat['target_category'] = train_data[:100]['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = mat.groupby(['target_category']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = build_tf(train_data, terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = build_tf(validation_data, terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.astype(bool).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document frequency per term\n",
    "df = x_train.astype(bool).sum(axis=0)\n",
    "df = np.log10(train_data.shape[0] / df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqM1YOG2Cq_m"
   },
   "outputs": [],
   "source": [
    "x_train = df * x_train\n",
    "y_train = train_data['category']\n",
    "\n",
    "x_val = df * x_val\n",
    "y_val = validation_data['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPXvODFxMxR7"
   },
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-LDfz6QalAB"
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred, categories):\n",
    "    conf_mat = np.zeros((len(categories), len(categories)))\n",
    "    for i in range(len(categories)):\n",
    "        for j in range(len(categories)):\n",
    "            conf_mat[i][j] = np.count_nonzero((y_pred == i) & (y_true == j).to_numpy())    \n",
    "    return pd.DataFrame(conf_mat, index=['Predicted ' + cat for cat in categories], columns=['True ' + cat for cat in categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    diff = (y_true == y_pred).to_numpy()\n",
    "    return np.count_nonzero(diff) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MRHkMUm1aldr"
   },
   "outputs": [],
   "source": [
    "def precision_recall(y_true, y_pred, categories):\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    recall = np.zeros(len(categories))\n",
    "    precision = np.zeros(len(categories))\n",
    "    \n",
    "    for i in range(len(categories)):\n",
    "        precision[i] = conf_mat[i][i] / conf_mat.sum(axis=0)[i]\n",
    "        recall[i] = conf_mat[i][i] / conf_mat.sum(axis=1)[i]\n",
    "        \n",
    "    return recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9Qm8er8al2U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h2FbSWowamGU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MnAXq9ZmZ4EC"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ehdWhnBX5irF"
   },
   "source": [
    "### Naive-Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Opl7jk3VHjq"
   },
   "source": [
    "#### Class Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mZ1fLk6m575b"
   },
   "outputs": [],
   "source": [
    "class Naive_Bayes:\n",
    "  def __init__(self, alpha):\n",
    "      self.alpha = alpha\n",
    "    \n",
    "  def predict(self, x_test):\n",
    "      test_pred = pd.DataFrame(columns = ['category'], index = x_test.index)\n",
    "      for doc_idx in x_test.index:\n",
    "        print(doc_idx)\n",
    "        doc = x_test.loc[doc_idx]\n",
    "        terms = list(set(text_to_words(doc.body) + text_to_words(doc.title)))         \n",
    "        scores = pd.DataFrame(index = self.class_probs.index)        \n",
    "        for c in self.class_probs.index:\n",
    "            scores.loc[c] = self.class_probs.loc[c] + self.term_probs[terms].sum(axis=1).loc[c]                      \n",
    "      return test_pred\n",
    "\n",
    "  def fit(self, tf_mat):\n",
    "      tf_mat.loc[:, tf_mat.columns != 'target_category'] = tf_mat.loc[:, tf_mat.columns != 'target_category'] + self.alpha  \n",
    "      self.class_probs = np.log10(tf_mat['target_category'].value_counts() / tf_mat['target_category'].shape[0]) \n",
    "      self.term_probs = np.log10(tf_mat.groupby(['target_category']).sum())\n",
    "      print(self.term_probs.head())\n",
    "      self.term_probs = self.term_probs.sub(pd.Series(np.log10(tf_mat.groupby(['target_category']).sum().sum(axis=1)).tolist(), index=self.term_probs.index))\n",
    "      print(self.term_probs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2q_d1yfTWQ3T"
   },
   "source": [
    "#### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = Naive_Bayes(alpha = 0.1)\n",
    "nb_model.fit(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb_model.predict(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uSvPO5OT5yIq"
   },
   "source": [
    "### K Nearest Neighbor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Opl7jk3VHjq"
   },
   "source": [
    "#### Class Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mZ1fLk6m575b"
   },
   "outputs": [],
   "source": [
    "class KNN:\n",
    "  def __init__(self, k, method):\n",
    "      self.k = k\n",
    "      self.method = method\n",
    "    \n",
    "\n",
    "  def predict(self, x_test):\n",
    "      test_pred = pd.DataFrame(columns = ['category'], index = x_test.index)\n",
    "      dist_matrix = self.distance_matrix(x_test)\n",
    "      \n",
    "      for i in range(0, len(x_test)):\n",
    "          neighbor_indexes = dist_matrix[i, :].argsort()[0:self.k] \n",
    "          majority = self.y.iloc[neighbor_indexes].mode()\n",
    "          test_pred.at[x_test.index[i], 'category'] = majority.at[0]\n",
    "\n",
    "      return test_pred\n",
    "\n",
    "\n",
    "  def distance_matrix(self, x_test):\n",
    "      if self.method == 'c':\n",
    "          return np.dot(self.x / np.linalg.norm(self.x), (x_test / np.linalg.norm(x_test)).T)\n",
    "\n",
    "      if self.method == 'e':\n",
    "          dist_matrix = np.zeros((x_test.shape[0], self.x.shape[0]))\n",
    "          dist_matrix = - 2 * np.dot(x_test, self.x.T).T\n",
    "          dist_matrix += np.diag((np.dot(x_test, x_test.T)))\n",
    "          dist_matrix = dist_matrix.T\n",
    "          dist_matrix += np.diag((np.dot(self.x, self.x.T)))\n",
    "          return np.sqrt(dist_matrix)\n",
    "\n",
    "\n",
    "  def fit(self, x, y):\n",
    "      self.x = x\n",
    "      self.y = y   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2q_d1yfTWQ3T"
   },
   "source": [
    "#### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "26FIrG5bVBjI"
   },
   "outputs": [],
   "source": [
    "knn_model = KNN(k=3, method='e')\n",
    "knn_model.fit(x_val, y_val)\n",
    "y_pred = knn_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 866,
     "status": "ok",
     "timestamp": 1589547290053,
     "user": {
      "displayName": "Yasamin Tabatabaee",
      "photoUrl": "",
      "userId": "07445355406834081164"
     },
     "user_tz": -270
    },
    "id": "NuYsS5kAZrlQ",
    "outputId": "ccdfbd60-981a-4046-8916-511aaebdb0e0"
   },
   "outputs": [],
   "source": [
    "accuracy(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uSvPO5OT5yIq"
   },
   "source": [
    "### Preprocessing Effect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [t for t in tokens if not t in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemmatize_text(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def stem_text(tokens):\n",
    "    stemmer = PorterStemmer() \n",
    "    return [stemmer.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = remove_stopwords(text_to_words(train_data.loc[0].body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize_text(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uSvPO5OT5yIq"
   },
   "source": [
    "### SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyper-parameter tuning with GridSearchCV\n",
    "\n",
    "params = {'C': [1, 10]}\n",
    "svm_model = svm.SVC(kernel='linear')\n",
    "svm_model = GridSearchCV(estimator = svm_model, param_grid = params, cv = 5)\n",
    "\n",
    "svm_model.fit(x_train, y_train)\n",
    "print(\"Validation accuracy = \", svm_model.score(x_val, y_val))\n",
    "print(\"Best params = \", svm_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uSvPO5OT5yIq"
   },
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = [100, 200, 300]\n",
    "max_depth = [5, 10, 15]\n",
    "\n",
    "params = {'n_estimators': n_estimators, \n",
    "          'max_depth': max_depth,}\n",
    "\n",
    "rf_m### Random Forest\n",
    "odel = RandomForestClassifier()\n",
    "rf_model = GridSearchCV(estimator = rf_model, param_grid = params, cv = 5)\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Validation accuracy = \", rf_model.score(x_val, y_val))\n",
    "print(\"Best params = \", rf_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Means:\n",
    "    \n",
    "  def __init__(self, k, threshold = 0.01, max_iter = 100):\n",
    "      self.k = k\n",
    "      self.threshold = threshold\n",
    "      self.max_iter = max_iter\n",
    "    \n",
    "\n",
    "\n",
    "  def fit(self, x, y):\n",
    "      self.x = x\n",
    "      self.y = y   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_model = K_Means(k=3)\n",
    "km_model.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne_results = tsne.fit_transform(data_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['tsne-2d-one'] = tsne_results[:,0]\n",
    "df_subset['tsne-2d-two'] = tsne_results[:,1]\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    data=df_subset,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = Word2Vec(window=2, size=300)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Classification_Clustering.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
